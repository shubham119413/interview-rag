# ğŸ§  Interview RAG â€” AI-Powered Interview Insights

Product managers, researchers, and hiring managers record dozens of interviews weekly â€” but extracting insights, themes, and key takeaways is slow and inconsistent. They want to ask questions directly from their corpus of interviews (â€œWhat themes emerged around pricing?â€ or â€œSummarize candidate strengthsâ€), but current tools: 
- Are expensive (per-token costs in OpenAI, Gemini APIs).
- Are opaque (no visibility into retrieval quality).
- Lack local deployment options for sensitive data.
- Have high latency, especially when transcribing or embedding new data.

**Interview RAG** is a lightweight Retrieval-Augmented Generation (RAG) app built for product managers and researchers to analyze interviews and summarize insights from PDFs, audio, and video files â€” all locally and cost-efficiently. It uses:

- âœ… FastAPI for backend API
- âœ… Streamlit for front-end
- âœ… Whisper for transcription
- âœ… SentenceTransformers + FAISS for retrieval
- âœ… Gemini 2.0 Flash for AI-powered answers
- âœ… Progress tracked in the UI for better debuggability

---

## âš™ï¸ Architecture Overview
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚      Streamlit UI        â”‚
            â”‚  (upload + ask + debug)  â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚       FastAPI Backend     â”‚
            â”‚  - Async upload + status  â”‚
            â”‚  - Whisper + pdf extract  â”‚
            â”‚  - Chunk + FAISS embed    â”‚
            â”‚  - Gemini QA/Summary API  â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚  FAISS Vector DB (in-memory) â”‚
         â”‚                             â”‚
         â”‚  Text chunks + embeddings    â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜




### ğŸš€ Features
- Upload and process:PDF documents, Audio files (.mp3, .wav), Video files (.mp4, .mov)
- Transcribes audio/video using Whisper
- Extracts text from PDFs
- Generates embeddings using SentenceTransformers
- Creates short/long contextual chunks for efficient retreival
- Stores embeddings in FAISS
- Answers questions using Gemini 2.0 Flash

---


## ğŸ§© How to Run Locally: Detailed steps

### 1. Clone the repo
```bash
git clone https://github.com/shubham119413/interview-rag.git
cd interview-rag
```

### 2. Create a virtual environment
```bash
python3 -m venv venv
source venv/bin/activate   # On Mac/Linux
venv\Scripts\activate      # On Windows
```

### 3. Install dependencies
```bash
pip install -r requirements.txt
```

### 4. Add your Gemini API key

Create a file named .env in the project root:
```bash
GEMINI_API_KEY=your_api_key_here
```

(If you donâ€™t have a key, create one at https://aistudio.google.com/app/apikey
)

### ğŸš€ Run Locally
**Step 1 â€” Start the backend (FastAPI)**
```bash
uvicorn main:app --reload --port 8000
```

This starts the server at http://127.0.0.1:8000/docs
.

**Step 2 â€” Start the frontend (Streamlit)**

Open a new terminal (while keeping FastAPI running):
```bash
streamlit run app.py
```

You can now upload files, view real-time progress, and ask questions through the UI.
