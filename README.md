# ğŸ§  Interview RAG â€” AI-Powered Interview Insights

**Interview RAG** is a lightweight Retrieval-Augmented Generation (RAG) app built for product managers and researchers to analyze interviews and summarize insights from PDFs, audio, and video files â€” all locally and cost-efficiently. It uses:

- âœ… FastAPI for backend API
- âœ… Streamlit for front-end
- âœ… Whisper for transcription
- âœ… SentenceTransformers + FAISS for retrieval
- âœ… Gemini 2.0 Flash for AI-powered answers
- âœ… Progress tracked for better debuggability

---

## âš™ï¸ Architecture Overview
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚      Streamlit UI        â”‚
            â”‚  (upload + ask + debug)  â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚       FastAPI Backend     â”‚
            â”‚  - Async upload + status  â”‚
            â”‚  - Whisper + pdf extract  â”‚
            â”‚  - Chunk + FAISS embed    â”‚
            â”‚  - Gemini QA/Summary API  â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚  FAISS Vector DB (in-memory) â”‚
         â”‚                             â”‚
         â”‚  Text chunks + embeddings    â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜




### ğŸš€ Features
- Upload and process:PDF documents, Audio files (.mp3, .wav), Video files (.mp4, .mov)
- Transcribes audio/video using Whisper
- Extracts text from PDFs
- Generates embeddings using SentenceTransformers
- Creates short/long contextual chunks for efficient retreival
- Stores embeddings in FAISS
- Answers questions using Gemini 2.0 Flash

---
## ğŸ› ï¸ How to Run Locally

1. Install dependencies:
    pip install -r requirements.txt

2. Create a `.env` file with your Gemini key:
    GEMINI_API_KEY=your-gemini-api-key-here

3. Run the FastAPI server:
    uvicorn main:app --host=0.0.0.0 --port=8000 --reload

Then open:
    http://localhost:8000/docs


## ğŸ§© Detailed steps

### 1. Clone the repo
```bash
git clone https://github.com/shubham119413/interview-rag.git
cd interview-rag
```

### 2. Create a virtual environment
```bash
python3 -m venv venv
source venv/bin/activate   # On Mac/Linux
venv\Scripts\activate      # On Windows
```

### 3. Install dependencies
```bash
pip install -r requirements.txt
```

### 4. Add your Gemini API key

Create a file named .env in the project root:
```bash
GEMINI_API_KEY=your_api_key_here
```

(If you donâ€™t have a key, create one at https://aistudio.google.com/app/apikey
)

### ğŸš€ Run Locally
**Step 1 â€” Start the backend (FastAPI)**
```bash
uvicorn main:app --reload --port 8000
```

This starts the server at http://127.0.0.1:8000/docs
.

**Step 2 â€” Start the frontend (Streamlit)**

Open a new terminal (while keeping FastAPI running):
```bash
streamlit run app.py
```

You can now upload files, view real-time progress, and ask questions through the UI.
