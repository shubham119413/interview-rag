# ğŸ§  Interview RAG â€” AI-Powered Interview Insights

**Interview RAG** is a lightweight Retrieval-Augmented Generation (RAG) app built for product managers and researchers to analyze interviews and summarize insights from PDFs, audio, and video files â€” all locally and cost-efficiently.

---

## âš™ï¸ Architecture Overview
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚      Streamlit UI        â”‚
            â”‚  (upload + ask + debug)  â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚       FastAPI Backend     â”‚
            â”‚  - Async upload + status  â”‚
            â”‚  - Whisper + pdf extract  â”‚
            â”‚  - Chunk + FAISS embed    â”‚
            â”‚  - Gemini QA/Summary API  â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚  FAISS Vector DB (in-memory) â”‚
         â”‚                             â”‚
         â”‚  Text chunks + embeddings    â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜


### Components
- **FastAPI** â†’ handles file upload, transcription, embedding, and Gemini calls  
- **Streamlit** â†’ frontend to upload, visualize progress, and query  
- **Whisper (base)** â†’ transcribes audio/video files  
- **FAISS Index** â†’ semantic search over text chunks  
- **Gemini API** â†’ generates contextual answers  

---

## ğŸ§© 1ï¸âƒ£ Local Setup Steps

### 1. Clone the repo
```bash
git clone https://github.com/shubham119413/interview-rag.git
cd interview-rag

2. Create a virtual environment
python3 -m venv venv
source venv/bin/activate   # On Mac/Linux
venv\Scripts\activate      # On Windows

3. Install dependencies
pip install -r requirements.txt

4. Add your Gemini API key

Create a file named .env in the project root:

GEMINI_API_KEY=your_api_key_here


(If you donâ€™t have a key, create one at https://aistudio.google.com/app/apikey
)

ğŸš€ 2ï¸âƒ£ Run Locally
Step 1 â€” Start the backend (FastAPI)
uvicorn main:app --reload --port 8000


This starts the server at http://127.0.0.1:8000/docs
.

Step 2 â€” Start the frontend (Streamlit)

Open a new terminal (while keeping FastAPI running):

streamlit run app.py


You can now upload files, view real-time progress, and ask questions through the UI.